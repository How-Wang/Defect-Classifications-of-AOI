{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Defect Classifications of AOI"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install --upgrade scipy\n","!pip install --upgrade scikit-image"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import torchvision.models as models\n","\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","import os\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["from skimage.feature import graycomatrix, graycoprops"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["EPOCHS = 100"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train_csv_file_path = 'aoi/train.csv'\n","test_csv_file_path = 'aoi/test.csv'\n","train_images_path = 'aoi/train_images/'\n","test_images_path = 'aoi/test_images/'"]},{"cell_type":"markdown","metadata":{},"source":["## Get file and score"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["def Drawloss(loss_list, val_loss_list):\n","    lens = len(loss_list)\n","    fig = plt.figure(figsize=(8, 5))\n","    fig.add_subplot(2,2,(1,4))\n","    plt.style.use(\"ggplot\")\n","\n","    plt.plot(range(1, lens+1), loss_list, label=\"train_loss\")\n","    plt.plot(range(1, lens+1), val_loss_list, label=\"val_loss\")\n","\n","    plt.xlabel(\"Epoch #\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend(loc=\"upper right\")\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["def val_accuracy(model_path):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if device.type == 'cuda':\n","        model = torch.load(model_path)\n","    else:\n","        model = torch.load(model_path, map_location=torch.device('cpu'))\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        \n","        accuracy = 100 * correct / total\n","        print(f\"{model_path}, Val Accuracy: {accuracy:.2f}%\")"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def test_result(model_path, csv_filename):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if device.type == 'cuda':\n","        model = torch.load(model_path)\n","    else:\n","        model = torch.load(model_path, map_location=torch.device('cpu'))\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    predicted_list = []\n","    with torch.no_grad():\n","        for images, labels in tqdm(test_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            predicted_list.append(predicted.item())\n","            \n","    test_df['Label'] = predicted_list\n","    test_df.to_csv(f'{csv_filename}', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Data preprocess"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(train_csv_file_path)\n","test_df = pd.read_csv(test_csv_file_path)"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["2528"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(train_df)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, csv_path, images_folder, transform = False):\n","        self.df = pd.read_csv(csv_path)\n","        self.images_folder = images_folder\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        filename = self.df.loc[index, \"ID\"]\n","        label = self.df.loc[index, \"Label\"].item()\n","        image = Image.open(os.path.join(self.images_folder, filename))\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","])\n","test_transform = transforms.Compose([\n","    transforms.ToTensor()\n","])"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["dataset = CustomDataset(train_csv_file_path,train_images_path, transform=transform)\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset, [0.9, 0.1])\n","test_dataset = CustomDataset(test_csv_file_path,test_images_path, transform=test_transform)\n","\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 1, 512, 512])\n","torch.Size([32])\n"]}],"source":["for images, labels in train_dataloader:\n","    print(images.shape)\n","    print(labels.shape)\n","    break"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["class EarlyStopper:\n","    def __init__(self, model_path, patience=40, min_delta=0.001):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.model_path = model_path\n","        self.counter = 0\n","        self.min_val_loss = np.inf\n","\n","    def check(self, val_loss, model):\n","        if val_loss < self.min_val_loss:\n","            self.min_val_loss = val_loss\n","            self.counter = 0\n","            torch.save(model, self.model_path)\n","        elif val_loss > (self.min_val_loss + self.min_delta):\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                return True\n","        return False "]},{"cell_type":"markdown","metadata":{},"source":["## 2. PSPNet with deeper Model\n","> score：0.9802712\n","- extract feature based on Conv\n","- Use Pyramid Pooling, Onebyone Conv\n","- Append Upsampling\n","- Conv + Linear to classify\n","- all from scratch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_path = f'PSPNetDeeper_epoch{EPOCHS}.pt'\n","predict_csv_path = f'PSPNetDeeper_epoch{EPOCHS}.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class PSPNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(PSPNet, self).__init__()\n","        \n","        # Conv layers\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1), # output size (N, 16, 512, 512)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 16, 256, 256)\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), # output size (N, 32, 256, 256)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 32, 128, 128)\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), # output size (N, 64, 128, 128)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 64, 64)\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # output size (N, 128, 64, 64)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 128, 32, 32)\n","        )\n","        # Spatial Pyramid Pooling layers\n","        self.pool1 = nn.AdaptiveMaxPool2d((1, 1)) # output size (N, 128, 1, 1)\n","        self.pool2 = nn.AdaptiveMaxPool2d((2, 2)) # output size (N, 128, 2, 2)\n","        self.pool3 = nn.AdaptiveMaxPool2d((3, 3)) # output size (N, 128, 3, 3)\n","        self.pool4 = nn.AdaptiveMaxPool2d((6, 6)) # output size (N, 128, 6, 6)\n","        self.con1 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 1, 1)\n","        self.con2 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 2, 2)\n","        self.con3 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 3, 3)\n","        self.con4 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 6, 6)\n","        # Upsampling layers\n","        self.upsample1 = nn.Upsample(scale_factor=32/1, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample2 = nn.Upsample(scale_factor=32/2, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample3 = nn.Upsample(scale_factor=32/3, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample4 = nn.Upsample(scale_factor=32/6, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        # Conv Classifier layers\n","        self.classifier = nn.Sequential(\n","            nn.Conv2d(in_channels=132, out_channels=64, kernel_size=3, stride=2, padding=1), # output size (N, 64, 16, 16)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 8, 8)\n","            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1), # output size (N, 32, 4, 4)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 32, 2, 2)\n","            nn.Flatten(), # output size (N, 32 * 2* 2)\n","            nn.Linear(32 * 2 * 2, 32), # output size (N, 32)\n","            nn.ReLU(),\n","            nn.Linear(32, num_classes), # output size (N, 6)\n","        )\n","        \n","    def forward(self, x):\n","        # CNN layers\n","        x = self.features(x)\n","        \n","        # Spatial Pyramid Pooling\n","        x1 = self.pool1(x)\n","        x1 = self.con1(x1) \n","        x2 = self.pool2(x)\n","        x2 = self.con2(x2)\n","        x3 = self.pool3(x)\n","        x3 = self.con3(x3)\n","        x4 = self.pool4(x)\n","        x4 = self.con4(x4)\n","        \n","        # Upsampling\n","        x1 = self.upsample1(x1)\n","        x2 = self.upsample2(x2)\n","        x3 = self.upsample3(x3)\n","        x4 = self.upsample4(x4)\n","        \n","        # Concatenate the pooled features\n","        x = torch.cat((x1, x2, x3, x4, x), dim=1) # output size (N, 132, 32, 32)\n","        \n","        # Classifier\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = PSPNet(num_classes=6).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","loss_list = []\n","val_loss_list = []\n","early_stopper = EarlyStopper(model_path = model_path)\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for images, labels in train_dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    loss_list.append(loss.item())\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        tmp_loss_list = []\n","        for images, labels in val_dataloader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            val_loss = criterion(outputs, labels)\n","            tmp_loss_list.append(val_loss.item())\n","        avg_val_loss = sum(tmp_loss_list)/len(tmp_loss_list)\n","        val_loss_list.append(avg_val_loss)\n","        if early_stopper.check(avg_val_loss, model):\n","            print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f},\\nEarly stop in {epoch+1}!!')\n","            break\n","            \n","    if (epoch+1) % 1 == 0 or epoch == 0:\n","        print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Drawloss(loss_list, val_loss_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# torch.save(model, model_path)\n","val_accuracy(model_path)\n","test_result(model_path, predict_csv_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 2.5 PSPNet + GLCM features\n","> score：0.9815043\n","- extract feature based on Conv\n","- Use Pyramid Pooling, Onebyone Conv\n","- Append Upsampling\n","- Conv + Linear to classify\n","- Add a GLCM features\n","- all from scratch"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["model_path = f'PSPNetGLCM_epoch{EPOCHS}.pt'\n","predict_csv_path = f'PSPNetGLCM_epoch{EPOCHS}.csv'"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["def GLCM_features(image):\n","    image = np.array(image)\n","    image = (image * 255).astype(np.uint8)\n","    glcm_features = torch.empty(25, dtype=torch.float32)\n","\n","    #5 configuration for the grey-level co-occurrence matrix calculation\n","    dists = [[1],[3],[5],[3],[3]]\n","    angles = [[0],[0],[0],[np.pi/4],[np.pi/2]]\n","\n","    for j ,(dist, angle) in enumerate(zip(dists, angles)):\n","        GLCM = graycomatrix(image, dist, angle) \n","        glcm_features[j*5] = torch.tensor(graycoprops(GLCM, 'energy')[0], dtype=torch.float32)\n","        glcm_features[j*5 + 1] = torch.tensor(graycoprops(GLCM, 'correlation')[0] , dtype=torch.float32)   \n","        glcm_features[j*5 + 2] = torch.tensor(graycoprops(GLCM, 'dissimilarity')[0], dtype=torch.float32)\n","        glcm_features[j*5 + 3] = torch.tensor(graycoprops(GLCM, 'homogeneity')[0], dtype=torch.float32)\n","        glcm_features[j*5 + 4] = torch.tensor(graycoprops(GLCM, 'contrast')[0], dtype=torch.float32)\n","        \n","    return glcm_features"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2528/2528 [00:27<00:00, 90.45it/s]\n"]}],"source":["GLCM_train_features_list = []\n","Feature_dataset = CustomDataset(train_csv_file_path,train_images_path, transform=transform)\n","Feature_dataloader = DataLoader(Feature_dataset, batch_size=1, shuffle=False)\n","for image, _ in tqdm(Feature_dataloader):\n","    glcm_feature = GLCM_features(torch.squeeze(image))\n","    GLCM_train_features_list.append(glcm_feature)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["GLCM_test_features_list = []\n","Feature_dataset = CustomDataset(test_csv_file_path, test_images_path, transform=test_transform)\n","Feature_dataloader = DataLoader(Feature_dataset, batch_size=1, shuffle=False)\n","for image, _ in tqdm(Feature_dataloader):\n","    glcm_feature = GLCM_features(torch.squeeze(image))\n","    GLCM_test_features_list.append(glcm_feature)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class GLCMDataset(Dataset):\n","    def __init__(self, csv_path, images_folder, transform = False, train= True):\n","        self.df = pd.read_csv(csv_path)\n","        self.images_folder = images_folder\n","        self.transform = transform\n","        self.train = train\n","\n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        filename = self.df.loc[index, \"ID\"]\n","        label = self.df.loc[index, \"Label\"].item()\n","        image = Image.open(os.path.join(self.images_folder, filename))\n","        if self.train == True:\n","            glcm_feature = GLCM_train_features_list[index]\n","        else:\n","            glcm_feature = GLCM_test_features_list[index]\n","            \n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label, glcm_feature"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = GLCMDataset(train_csv_file_path,train_images_path, transform=transform, train=True)\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset, [0.9, 0.1])\n","test_dataset = GLCMDataset(test_csv_file_path,test_images_path, transform=test_transform, train=False)\n","\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for images, labels, glcm_features in train_dataloader:\n","    print(images.shape)\n","    print(labels.shape)\n","    print(glcm_features.shape)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class PSPNetGLCM(nn.Module):\n","    def __init__(self, num_classes):\n","        super(PSPNetGLCM, self).__init__()\n","        \n","        # Conv layers\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1), # output size (N, 16, 512, 512)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 16, 256, 256)\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), # output size (N, 32, 256, 256)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 32, 128, 128)\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), # output size (N, 64, 128, 128)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 64, 64)\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # output size (N, 128, 64, 64)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 128, 32, 32)\n","        )\n","        # Spatial Pyramid Pooling layers\n","        self.pool1 = nn.AdaptiveMaxPool2d((1, 1)) # output size (N, 128, 1, 1)\n","        self.pool2 = nn.AdaptiveMaxPool2d((2, 2)) # output size (N, 128, 2, 2)\n","        self.pool3 = nn.AdaptiveMaxPool2d((3, 3)) # output size (N, 128, 3, 3)\n","        self.pool4 = nn.AdaptiveMaxPool2d((6, 6)) # output size (N, 128, 6, 6)\n","        self.con1 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 1, 1)\n","        self.con2 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 2, 2)\n","        self.con3 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 3, 3)\n","        self.con4 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 6, 6)\n","        # Upsampling layers\n","        self.upsample1 = nn.Upsample(scale_factor=32/1, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample2 = nn.Upsample(scale_factor=32/2, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample3 = nn.Upsample(scale_factor=32/3, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample4 = nn.Upsample(scale_factor=32/6, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        \n","        # Conv Classifier layers\n","        self.nn_classifier = nn.Sequential(\n","            nn.Conv2d(in_channels=132, out_channels=64, kernel_size=3, stride=2, padding=1), # output size (N, 64, 16, 16)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 8, 8)\n","            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1), # output size (N, 32, 4, 4)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 32, 2, 2)\n","            nn.Flatten(), # output size (N, 32 * 2* 2)\n","            nn.Linear(32 * 2 * 2, 24), # output size (N, 24)\n","            nn.ReLU(),\n","        )\n","        self.glcm_classifier= nn.Sequential(\n","            nn.Linear(25, 8), # output size (N, 8)\n","            nn.ReLU(),\n","        )\n","        self.final_classifier = nn.Sequential(\n","            nn.Linear(32, num_classes) # output size (N, num_classes=6)\n","        )\n","        \n","    def forward(self, x_input, x_glcm):\n","        # CNN layers\n","        x = self.features(x_input)\n","        \n","        # Spatial Pyramid Pooling\n","        x1 = self.pool1(x)\n","        x1 = self.con1(x1) \n","        x2 = self.pool2(x)\n","        x2 = self.con2(x2)\n","        x3 = self.pool3(x)\n","        x3 = self.con3(x3)\n","        x4 = self.pool4(x)\n","        x4 = self.con4(x4)\n","        \n","        # Upsampling\n","        x1 = self.upsample1(x1)\n","        x2 = self.upsample2(x2)\n","        x3 = self.upsample3(x3)\n","        x4 = self.upsample4(x4)\n","        \n","        # Concatenate the pooled features\n","        x = torch.cat((x1, x2, x3, x4, x), dim=1) # output size (N, 132, 32, 32)\n","        \n","        # Classifier\n","        x = self.nn_classifier(x) # output size (N, 24)\n","        \n","        # Get GLCM features \n","        x_glcm = self.glcm_classifier(x_glcm) # output size (N, 8)\n","        \n","        # Concatenate nn features and GLCM features\n","        x = torch.cat((x, x_glcm), dim=1) # output size (N, 32, 32)\n","        \n","        # final classifier\n","        x = self.final_classifier(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = PSPNetGLCM(num_classes=6).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","loss_list = []\n","val_loss_list = []\n","early_stopper = EarlyStopper(model_path = model_path)\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for images, labels, glcm_features in tqdm(train_dataloader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        glcm_features = glcm_features.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(images, glcm_features)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    loss_list.append(loss.item())\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        tmp_loss_list = []\n","        for images, labels, glcm_features in val_dataloader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            glcm_features = glcm_features.to(device)\n","            \n","            outputs = model(images, glcm_features)\n","            val_loss = criterion(outputs, labels)\n","            tmp_loss_list.append(val_loss.item())\n","        avg_val_loss = sum(tmp_loss_list)/len(tmp_loss_list)\n","        val_loss_list.append(avg_val_loss)\n","        if early_stopper.check(avg_val_loss, model):\n","            print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f},\\nEarly stop in {epoch+1}!!')\n","            break\n","            \n","    if (epoch+1) % 1 == 0 or epoch == 0:\n","        print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def val_accuracy(model_path):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if device.type == 'cuda':\n","        model = torch.load(model_path)\n","    else:\n","        model = torch.load(model_path, map_location=torch.device('cpu'))\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels, glcm_features in tqdm(val_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            glcm_features = glcm_features.to(device)\n","            \n","            outputs = model(images, glcm_features)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        \n","        accuracy = 100 * correct / total\n","        print(f\"{model_path}, Val Accuracy: {accuracy:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def test_result(model_path, csv_filename):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if device.type == 'cuda':\n","        model = torch.load(model_path)\n","    else:\n","        model = torch.load(model_path, map_location=torch.device('cpu'))\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    predicted_list = []\n","    with torch.no_grad():\n","        for images, labels, glcm_features in tqdm(test_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            glcm_features = glcm_features.to(device)\n","            \n","            outputs = model(images, glcm_features)\n","            _, predicted = torch.max(outputs.data, 1)\n","            predicted_list.append(predicted.item())\n","            \n","    test_df['Label'] = predicted_list\n","    test_df.to_csv(f'{csv_filename}', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Drawloss(loss_list, val_loss_list)\n","val_accuracy(model_path)\n","test_result(model_path, predict_csv_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 2.6 PSPNet + GLCM + LBP\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_path = f'PSPNetGLCMLBP_epoch{EPOCHS}.pt'\n","predict_csv_path = f'PSPNetGLCMLBP_epoch{EPOCHS}.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from skimage.feature import local_binary_pattern\n","\n","def LBP_features(image):\n","    image = np.array(image)\n","    lbp = local_binary_pattern(image, P=8, R=1, method='uniform')\n","    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 10))\n","    lbp_hist = lbp_hist.astype(\"float\")\n","    lbp_hist /= (lbp_hist.sum() + 1e-6)  # Normalize\n","    return torch.tensor(lbp_hist, dtype=torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Tradi_features_list = []\n","Feature_dataset = CustomDataset(train_csv_file_path,train_images_path, transform=transform)\n","Feature_dataloader = DataLoader(Feature_dataset, batch_size=1, shuffle=False)\n","\n","for image, _ in tqdm(Feature_dataloader):\n","    glcm_features = GLCM_features(torch.squeeze(image))\n","    lbp_features = LBP_features(torch.squeeze(image))\n","    tradi_features = torch.cat((glcm_features, lbp_features), dim=0)\n","    Tradi_features_list.append(tradi_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class GLCM_LBPDataset(Dataset):\n","    def __init__(self, csv_path, images_folder, transform = False):\n","        self.df = pd.read_csv(csv_path)\n","        self.images_folder = images_folder\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        filename = self.df.loc[index, \"ID\"]\n","        label = self.df.loc[index, \"Label\"].item()\n","        image = Image.open(os.path.join(self.images_folder, filename))\n","        tradi_features = Tradi_features_list[index]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label, tradi_features"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = GLCM_LBPDataset(train_csv_file_path,train_images_path, transform=transform)\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset, [0.9, 0.1])\n","test_dataset = GLCM_LBPDataset(test_csv_file_path,test_images_path, transform=test_transform)\n","\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for images, labels, tradi_feature in train_dataloader:\n","    print(images.shape)\n","    print(labels.shape)\n","    print(tradi_feature.shape)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class PSPNetGLCMLBP(nn.Module):\n","    def __init__(self, num_classes):\n","        super(PSPNetGLCMLBP, self).__init__()\n","        \n","        # Conv layers\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1), # output size (N, 16, 512, 512)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 16, 256, 256)\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), # output size (N, 32, 256, 256)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 32, 128, 128)\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), # output size (N, 64, 128, 128)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 64, 64)\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # output size (N, 128, 64, 64)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 128, 32, 32)\n","        )\n","        # Spatial Pyramid Pooling layers\n","        self.pool1 = nn.AdaptiveMaxPool2d((1, 1)) # output size (N, 128, 1, 1)\n","        self.pool2 = nn.AdaptiveMaxPool2d((2, 2)) # output size (N, 128, 2, 2)\n","        self.pool3 = nn.AdaptiveMaxPool2d((3, 3)) # output size (N, 128, 3, 3)\n","        self.pool4 = nn.AdaptiveMaxPool2d((6, 6)) # output size (N, 128, 6, 6)\n","        self.con1 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 1, 1)\n","        self.con2 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 2, 2)\n","        self.con3 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 3, 3)\n","        self.con4 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 6, 6)\n","        # Upsampling layers\n","        self.upsample1 = nn.Upsample(scale_factor=32/1, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample2 = nn.Upsample(scale_factor=32/2, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample3 = nn.Upsample(scale_factor=32/3, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        self.upsample4 = nn.Upsample(scale_factor=32/6, mode='bilinear', align_corners=True) # output size (N, 1, 32, 32)\n","        \n","        # Conv Classifier layers\n","        self.nn_classifier = nn.Sequential(\n","            nn.Conv2d(in_channels=132, out_channels=64, kernel_size=3, stride=2, padding=1), # output size (N, 64, 16, 16)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 8, 8)\n","            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1), # output size (N, 32, 4, 4)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 32, 2, 2)\n","            nn.Flatten(), # output size (N, 32 * 2* 2)\n","            nn.Linear(32 * 2 * 2, 24), # output size (N, 24)\n","            nn.ReLU(),\n","        )\n","        self.tradi_classifier= nn.Sequential(\n","            nn.Linear(34, 8), # output size (N, 8)\n","            nn.ReLU(),\n","        )\n","        self.fusion_classifier = nn.Sequential(\n","            nn.Linear(32, num_classes) # output size (N, num_classes=6)\n","        )\n","        \n","    def forward(self, x_input, x_tradi):\n","        # CNN layers\n","        x = self.features(x_input)\n","        \n","        # Spatial Pyramid Pooling\n","        x1 = self.pool1(x)\n","        x1 = self.con1(x1) \n","        x2 = self.pool2(x)\n","        x2 = self.con2(x2)\n","        x3 = self.pool3(x)\n","        x3 = self.con3(x3)\n","        x4 = self.pool4(x)\n","        x4 = self.con4(x4)\n","        \n","        # Upsampling\n","        x1 = self.upsample1(x1)\n","        x2 = self.upsample2(x2)\n","        x3 = self.upsample3(x3)\n","        x4 = self.upsample4(x4)\n","        \n","        # Concatenate the pooled features\n","        x = torch.cat((x1, x2, x3, x4, x), dim=1) # output size (N, 132, 32, 32)\n","        \n","        # Classifier\n","        x = self.nn_classifier(x) # output size (N, 24)\n","        \n","        # Get Traditional features (GLCM + LBP)\n","        x_tradi = self.tradi_classifier(x_tradi) # output size (N, 8)\n","         \n","        \n","        # Concatenate nn features and GLCM features\n","        x = torch.cat((x, x_tradi), dim=1) # output size (N, 32, 32)\n","        \n","        # fusion classifier\n","        x = self.fusion_classifier(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = PSPNetGLCMLBP(num_classes=6).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","loss_list = []\n","val_loss_list = []\n","early_stopper = EarlyStopper(model_path = model_path)\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for images, labels, tradi_features in tqdm(train_dataloader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        tradi_features = tradi_features.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(images, tradi_features)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    loss_list.append(loss.item())\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        tmp_loss_list = []\n","        for images, labels, tradi_features in val_dataloader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            tradi_features = tradi_features.to(device)\n","            \n","            outputs = model(images, tradi_features)\n","            val_loss = criterion(outputs, labels)\n","            tmp_loss_list.append(val_loss.item())\n","        avg_val_loss = sum(tmp_loss_list)/len(tmp_loss_list)\n","        val_loss_list.append(avg_val_loss)\n","        if early_stopper.check(avg_val_loss, model):\n","            print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f},\\nEarly stop in {epoch+1}!!')\n","            break\n","            \n","    if (epoch+1) % 1 == 0 or epoch == 0:\n","        print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def val_accuracy(model_path):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if device.type == 'cuda':\n","        model = torch.load(model_path)\n","    else:\n","        model = torch.load(model_path, map_location=torch.device('cpu'))\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels, tradi_features in tqdm(val_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            tradi_features = tradi_features.to(device)\n","            \n","            outputs = model(images, tradi_features)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        \n","        accuracy = 100 * correct / total\n","        print(f\"{model_path}, Val Accuracy: {accuracy:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def test_result(model_path, csv_filename):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    if device.type == 'cuda':\n","        model = torch.load(model_path)\n","    else:\n","        model = torch.load(model_path, map_location=torch.device('cpu'))\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    predicted_list = []\n","    with torch.no_grad():\n","        for images, labels, tradi_features in tqdm(test_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            tradi_features = tradi_features.to(device)\n","            \n","            outputs = model(images, tradi_features)\n","            _, predicted = torch.max(outputs.data, 1)\n","            predicted_list.append(predicted.item())\n","            \n","    test_df['Label'] = predicted_list\n","    test_df.to_csv(f'{csv_filename}', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Drawloss(loss_list, val_loss_list)\n","val_accuracy(model_path)\n","test_result(model_path, predict_csv_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import the modules we'll need\n","from IPython.display import HTML\n","import pandas as pd\n","import numpy as np\n","import base64\n","\n","# function that takes in a dataframe and creates a text link to  \n","# download it (will only work for files < 2MB or so)\n","def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n","    csv = df.to_csv()\n","    b64 = base64.b64encode(csv.encode())\n","    payload = b64.decode()\n","    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n","    html = html.format(payload=payload,title=title,filename=filename)\n","    return HTML(html)\n","\n","# create a link to download the dataframe\n","create_download_link(test_df, filename=predict_csv_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Baseline\n","> second best, In feature layer, channels number half is better. Half score(16->32):0.9528976,Full score(32->64):0.9418002\n","- extract feature based on Conv\n","- Linear to classify\n","- all from scratch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_path = f'BaseDeeper_epoch{EPOCHS}.pt'\n","predict_csv_path = f'BaseDeeper_epoch{EPOCHS}.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class BasicCNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(BasicCNN, self).__init__()\n","        \n","        # Conv layers\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1), # output size (N, 16, 512, 512)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 16, 256, 256)\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), # output size (N, 32, 256, 256)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 32, 128, 128)\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), # output size (N, 64, 128, 128)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 64, 64)\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # output size (N, 128, 64, 64)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 128, 32, 32)\n","        )\n","        # Conv Classifier layers\n","        self.classifier = nn.Sequential(\n","            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1), # output size (N, 64, 16, 16)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 8, 8)\n","            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1), # output size (N, 32, 4, 4)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 32, 2, 2)\n","            nn.Flatten(), # output size (N, 32 * 2* 2)\n","            nn.Linear(32 * 2 * 2, 32), # output size (N, 32)\n","            nn.ReLU(),\n","            nn.Linear(32, num_classes), # output size (N, 6)\n","        )\n","        \n","    def forward(self, x):\n","        # CNN layers\n","        x = self.features(x)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = CustomDataset(train_csv_file_path,train_images_path, transform=transform)\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset, [0.9, 0.1])\n","test_dataset = CustomDataset(test_csv_file_path,test_images_path, transform=test_transform)\n","\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = BasicCNN(num_classes=6).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","loss_list = []\n","val_loss_list = []\n","early_stopper = EarlyStopper(model_path = model_path)\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for images, labels in train_dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    loss_list.append(loss.item())\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        tmp_loss_list = []\n","        for images, labels in val_dataloader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            val_loss = criterion(outputs, labels)\n","            tmp_loss_list.append(val_loss.item())\n","        avg_val_loss = sum(tmp_loss_list)/len(tmp_loss_list)\n","        val_loss_list.append(avg_val_loss)\n","        if early_stopper.check(avg_val_loss, model):\n","            print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f},\\nEarly stop in {epoch+1}!!')\n","            break\n","            \n","    if (epoch+1) % 1 == 0 or epoch == 0:\n","        print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Drawloss(loss_list, val_loss_list)\n","val_accuracy(model_path)\n","test_result(model_path, predict_csv_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 4. ResNet 18\n","> The worst no need to submit\n","- first layer 3 channels change to 1 channel\n","- last append a new linear \n","    - input size 1000 \n","    - output size class_num=6\n","- only train above 2 layers, other layer use pretrained ResNet18"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # 檢視 ResNet18 模型結構\n","# net = models.resnet18()\n","# print(net)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_path = f'ResNet18_epoch{EPOCHS}.pt'\n","predict_csv_path = f'ResNet18_epoch{EPOCHS}.pt'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNet, self).__init__()\n","        self.resnet = models.resnet18(pretrained=True)\n","        \n","        # Modify the first layer to accept single-channel input\n","        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        \n","        # Freeze the layers except the new conv1 and the classification layer\n","        for name, param in self.resnet.named_parameters():\n","            if 'conv1' in name:\n","                param.requires_grad = True\n","            else:\n","                param.requires_grad = False\n","        \n","        # Modify the classification layer\n","        self.classifier = nn.Linear(self.resnet.fc.out_features, num_classes)\n","        \n","    def forward(self, x):\n","        x = self.resnet(x)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Define the model\n","num_classes = 6\n","model = ResNet(num_classes).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","# Define the optimizer for fine-tuning using Adam with a single learning rate\n","fine_tune_params = list(model.resnet.conv1.parameters()) + list(model.classifier.parameters())\n","optimizer = torch.optim.Adam(fine_tune_params, lr=0.001, betas=(0.9, 0.999))\n","\n","loss_list = []\n","val_loss_list = []\n","early_stopper = EarlyStopper(model_path = model_path)\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for images, labels in train_dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    loss_list.append(loss.item())\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        tmp_loss_list = []\n","        for images, labels in val_dataloader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            val_loss = criterion(outputs, labels)\n","            tmp_loss_list.append(val_loss.item())\n","        avg_val_loss = sum(tmp_loss_list)/len(tmp_loss_list)\n","        val_loss_list.append(avg_val_loss)\n","        if early_stopper.check(avg_val_loss, model):\n","            print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f},\\nEarly stop in {epoch+1}!!')\n","            break\n","            \n","    if (epoch+1) % 1 == 0 or epoch == 0:\n","        print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Drawloss(loss_list, val_loss_list)\n","val_accuracy(model_path)\n","test_result(model_path, predict_csv_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. ResNet18 with PSPNet idea\n","> score: 0.9420468, worse then all from scratch\n","- first layer 3 channels change to 1 channel\n","- last append Pyramid Pooling layers, Onebyone Conv and Upsampling before ResNet18 layer4\n","- Conv + Linear to classify\n","- Train above 3 layers, other layer use pretrained ResNet18"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_path = f'ResNetPSPNet_epoch{EPOCHS}.pt'\n","predict_csv_path = f'ResNetPSPNet_epoch{EPOCHS}.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class ResNetPSPNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ResNetPSPNet, self).__init__()\n","        self.resnet = models.resnet18(pretrained=True)\n","        \n","        # Modify the first layer to accept single-channel input\n","        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        \n","        # Freeze the layers except the new conv1 and the classification layer\n","        for name, param in self.resnet.named_parameters():\n","            if 'conv1' in name:\n","                param.requires_grad = True\n","            else:\n","                param.requires_grad = False\n","        \n","        # Spatial Pyramid Pooling layers\n","        self.pool1 = nn.AdaptiveMaxPool2d((1, 1)) # output size (N, 512, 1, 1)\n","        self.pool2 = nn.AdaptiveMaxPool2d((2, 2)) # output size (N, 512, 2, 2)\n","        self.pool3 = nn.AdaptiveMaxPool2d((3, 3)) # output size (N, 512, 3, 3)\n","        self.pool4 = nn.AdaptiveMaxPool2d((6, 6)) # output size (N, 512, 6, 6)\n","        self.onebyonecon1 = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 1, 1)\n","        self.onebyonecon2 = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 2, 2)\n","        self.onebyonecon3 = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 3, 3)\n","        self.onebyonecon4 = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0) # output size (N, 1, 6, 6)\n","        # Upsampling layers\n","        self.upsample1 = nn.Upsample(scale_factor=16/1, mode='bilinear', align_corners=True) # output size (N, 1, 16, 16)\n","        self.upsample2 = nn.Upsample(scale_factor=16/2, mode='bilinear', align_corners=True) # output size (N, 1, 16, 16)\n","        self.upsample3 = nn.Upsample(scale_factor=16/3, mode='bilinear', align_corners=True) # output size (N, 1, 16, 16)\n","        self.upsample4 = nn.Upsample(scale_factor=16/6, mode='bilinear', align_corners=True) # output size (N, 1, 16, 16)\n","        # Conv Classifier layers\n","        self.classifier = nn.Sequential(\n","            nn.Conv2d(in_channels=516, out_channels=128, kernel_size=3, stride=2, padding=1), # output size (N, 128, 8, 8)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 128, 4, 4)\n","            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1), # output size (N, 64, 2, 2)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2), # output size (N, 64, 1, 1)\n","            nn.Flatten(), # output size (N, 64 * 1 * 1)\n","            nn.Linear(64, num_classes), # output size (N, 6)\n","        )\n","        \n","    def forward(self, x):\n","        x = self.resnet.conv1(x)\n","        x = self.resnet.bn1(x)\n","        x = self.resnet.relu(x)\n","        x = self.resnet.maxpool(x)\n","\n","        x = self.resnet.layer1(x)\n","        x = self.resnet.layer2(x)\n","        x = self.resnet.layer3(x)\n","        x = self.resnet.layer4(x)\n","        \n","        # Spatial Pyramid Pooling\n","        x1 = self.pool1(x)\n","        x1 = self.onebyonecon1(x1) \n","        x2 = self.pool2(x)\n","        x2 = self.onebyonecon2(x2)\n","        x3 = self.pool3(x)\n","        x3 = self.onebyonecon3(x3)\n","        x4 = self.pool4(x)\n","        x4 = self.onebyonecon4(x4)\n","        \n","        # Upsampling\n","        x1 = self.upsample1(x1)\n","        x2 = self.upsample2(x2)\n","        x3 = self.upsample3(x3)\n","        x4 = self.upsample4(x4)\n","        \n","        # Concatenate the pooled features\n","        x = torch.cat((x1, x2, x3, x4, x), dim=1) # output size (N, 516, 16, 16)\n","        \n","        # Classifier\n","        x = self.classifier(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Define the model\n","num_classes = 6\n","model = ResNetPSPNet(num_classes).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","# Define the optimizer for fine-tuning using Adam with a single learning rate\n","\n","# Create a list of parameters to optimize (conv1 and classifier)\n","parameters_to_optimize = [\n","    {'params': model.resnet.conv1.parameters()},\n","    {'params': model.onebyonecon1.parameters()},\n","    {'params': model.onebyonecon2.parameters()},\n","    {'params': model.onebyonecon3.parameters()},\n","    {'params': model.onebyonecon4.parameters()},\n","    {'params': model.classifier.parameters()},\n","]\n","optimizer = torch.optim.Adam(parameters_to_optimize, lr=0.001, betas=(0.9, 0.999))\n","\n","loss_list = []\n","val_loss_list = []\n","early_stopper = EarlyStopper(model_path = model_path)\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for images, labels in train_dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    loss_list.append(loss.item())\n","    \n","    \n","    model.eval()\n","    with torch.no_grad():\n","        tmp_loss_list = []\n","        for images, labels in val_dataloader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            val_loss = criterion(outputs, labels)\n","            tmp_loss_list.append(val_loss.item())\n","        avg_val_loss = sum(tmp_loss_list)/len(tmp_loss_list)\n","        val_loss_list.append(avg_val_loss)\n","        if early_stopper.check(avg_val_loss, model):\n","            print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f},\\nEarly stop in {epoch+1}!!')\n","            break\n","            \n","    if (epoch+1) % 1 == 0 or epoch == 0:\n","        print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {loss.item():.4f}, Val Loss:{avg_val_loss:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Drawloss(loss_list, val_loss_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_accuracy(model_path)\n","test_result(model_path, predict_csv_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
